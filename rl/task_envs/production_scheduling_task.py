import os
from production_system import ProductionSystem
import gymnasium as gym
from gymnasium.utils import seeding

class PrOPPlanEnv(gym.Env):
    '''
    Gym Environment of a production scheduling task that defines important functions
    such as get_obs(), step(), is_done(), compute_reward(), reset() etc.
    '''

    def __init__(self, production_system=None, **kwargs):
        print("PrOPPlanEnv: Started initializing...")
        self.seed()
        
        # Prepare production system
        super().__init__()
        self.production_system : ProductionSystem = production_system
        self._prepare_production_system()

        # TODO Define observation and action space dimensions here


        # Init logging

        # self.logging = True ############## for behavior cloning set self.logging = False ###############
        # train_sess = 'session_1/'
        # self.env_version = "0.1"
        # self.path_recorded_data = "./selflearningdata/" + train_sess
        # if not os.path.isdir(self.path_recorded_data):
        #     raise IOError("folder ", self.path_recorded_data, " does not exist yet! Please create this empty folder!")
        # self.steps_in_episode = 0
        # self.recorded_observations = None
        # self.recorded_actions = None
        # self.recorded_rewards = None
        # self.recorded_done = None


    # Env methods
    def seed(self, seed=None):
        self.np_random, seed = seeding.np_random(seed)
        return [seed]
    
    def _prepare_production_system(self):
        self.production_system.make_simulatable()

    def _production_system_sanity_check(self):
        # TODO Checks whether all functionally necessary attributes have reasonable values, e.g. there are Workers that can provide required capabilities,
        # outputs of operations are used elsewhere downstream etc.
        raise NotImplementedError
    
    def legal_actions(self):
        """
        Should return the legal actions at each turn, if it is not available, it can return
        the whole action space. At each turn, the game has to be able to handle one of returned actions.

        For complex game where calculating legal moves is too long, the idea is to define the legal actions
        equal to the action space but to return a negative reward if the action is illegal.

        Returns:
            An array of integers, subset of the action space.
        """
        legal_actions = self.production_system.get_legal_actions()
        return legal_actions
    
    def step(self, action):
        """
        Function executed each time step.
        Here we get the action execute it in a time step and retrieve the
        observations generated by that action.
        :param action:
        :return: obs, reward, done, info
        """
        print("PrOPPlanEnv: Starting a step...")
        self._set_action(action)
        obs = self._get_obs()
        done = self._is_done(obs)
        info = {}
        reward = self._compute_reward(obs, done)
        self.cumulated_episode_reward += reward
        print("PrOPPlanEnv: Step finished")
        if self.logging:
            self._log_step(obs, action, reward, done)
        return obs, reward, done, info

    def _log_step(self, obs, action, reward, done):
        """
            Saves obs, action, reward, done in one row of a flattened numpy array.
            One Episode is multiple number of rows in a 2d numpy array.
        """
        # TODO See openai/robot_env in SmartAssembly
        pass

    def reset(self):
        """
        Reset the game for a new game.

        Returns:
            Initial observation of the game.
        """
        print("PrOPPlanEnv: Resetting...")
        self.production_system.reset()
        obs = self._get_obs()
        print("PrOPPlanEnv: Finished resetting")
        return obs
    
    def _get_obs(self):
        """Returns the observation.
        """
        self.production_system.get_obs()

    def _init_env_variables(self):
        """Inits variables needed to be initialised each time we reset at the start
        of an episode.
        """
        raise NotImplementedError()

    def _set_action(self, action):
        """Applies the given action to the simulation.
        """
        self.production_system.set_action(action)

    def _is_done(self, observations):
        """Indicates whether or not the episode is done.
        """
        done = self.production_system.is_done()
        return done

    def _compute_reward(self, observations, done):
        """Calculates the reward to give based on the observations given.
        """
        raise NotImplementedError()

    def _env_setup(self, initial_qpos):
        """Initial configuration of the environment. Can be used to configure initial state
        and extract information from the simulation.
        """
        raise NotImplementedError()

    def _set_init_approach_pose(self):
        # TODO Adjust from SmartAssembly to PrOPPlan (theory: instead of bringing the robot back to initial pose, prepare Propplan GUI?)
        raise NotImplementedError()


